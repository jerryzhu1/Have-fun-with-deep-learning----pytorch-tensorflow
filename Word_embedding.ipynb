{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Word_embedding.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jerryzhu1/Have-fun-with-deep-learning----pytorch-tensorflow/blob/master/Word_embedding.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ySdzkTcfevH",
        "colab_type": "code",
        "outputId": "683ed450-c837-4f91-eb36-190bf7c8f93c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "13OhRC6_iGia",
        "colab_type": "code",
        "outputId": "b6c57de4-8a2d-4d32-cc40-462714d20747",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        }
      },
      "source": [
        "import glob\n",
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "!pip install tensorflow-gpu==2.0.0-beta1\n",
        "# !pip install tensorflow==2.0.0-beta1\n",
        "import pickle\n",
        "\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import re\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from keras.utils import to_categorical\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow-gpu==2.0.0-beta1 in /usr/local/lib/python3.6/dist-packages (2.0.0b1)\n",
            "Requirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-beta1) (1.16.4)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-beta1) (3.7.1)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-beta1) (0.1.7)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-beta1) (1.1.0)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-beta1) (0.2.2)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-beta1) (1.11.2)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-beta1) (1.1.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-beta1) (0.33.4)\n",
            "Requirement already satisfied: tf-estimator-nightly<1.14.0.dev2019060502,>=1.14.0.dev2019060501 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-beta1) (1.14.0.dev2019060501)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-beta1) (1.15.0)\n",
            "Requirement already satisfied: tb-nightly<1.14.0a20190604,>=1.14.0a20190603 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-beta1) (1.14.0a20190603)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-beta1) (1.0.8)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-beta1) (0.7.1)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-beta1) (1.12.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-beta1) (0.8.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow-gpu==2.0.0-beta1) (41.1.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.14.0a20190604,>=1.14.0a20190603->tensorflow-gpu==2.0.0-beta1) (3.1.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.14.0a20190604,>=1.14.0a20190603->tensorflow-gpu==2.0.0-beta1) (0.15.5)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow-gpu==2.0.0-beta1) (2.8.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FpRIGRb8fQyu",
        "colab_type": "code",
        "outputId": "c7a69c3e-6aea-4f86-e36f-46a4b5794adb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "import re\n",
        "nltk.download('stopwords')\n",
        "stop_words = set(stopwords.words('english'))\n",
        "porter = PorterStemmer()\n",
        "\n",
        "REPLACE_BY_SPACE_RE = re.compile('[/(){}\\[\\]\\|@,;]')\n",
        "BAD_SYMBOLS_RE = re.compile('[^a-z #+_]')\n",
        "\n",
        "def clean_text(text):\n",
        "    text = str(text).lower() \n",
        "    text = REPLACE_BY_SPACE_RE.sub(' ', text) \n",
        "    text = BAD_SYMBOLS_RE.sub('', text) \n",
        "    text = ' '.join(porter.stem(word) for word in text.split() if word not in stop_words) \n",
        "    return text"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4dxvGZ9zr5tg",
        "colab_type": "code",
        "outputId": "687aefaf-6fc7-4fa9-be38-7037a85ffaa5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 544
        }
      },
      "source": [
        "from tensorflow.python.client import device_lib\n",
        "print(device_lib.list_local_devices())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[name: \"/device:CPU:0\"\n",
            "device_type: \"CPU\"\n",
            "memory_limit: 268435456\n",
            "locality {\n",
            "}\n",
            "incarnation: 17825944863658724207\n",
            ", name: \"/device:XLA_GPU:0\"\n",
            "device_type: \"XLA_GPU\"\n",
            "memory_limit: 17179869184\n",
            "locality {\n",
            "}\n",
            "incarnation: 14781377401161120269\n",
            "physical_device_desc: \"device: XLA_GPU device\"\n",
            ", name: \"/device:XLA_CPU:0\"\n",
            "device_type: \"XLA_CPU\"\n",
            "memory_limit: 17179869184\n",
            "locality {\n",
            "}\n",
            "incarnation: 9977661843109918919\n",
            "physical_device_desc: \"device: XLA_CPU device\"\n",
            ", name: \"/device:GPU:0\"\n",
            "device_type: \"GPU\"\n",
            "memory_limit: 14892338381\n",
            "locality {\n",
            "  bus_id: 1\n",
            "  links {\n",
            "  }\n",
            "}\n",
            "incarnation: 15815407596330777298\n",
            "physical_device_desc: \"device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\"\n",
            "]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZUhcpV7_g3Pf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = []\n",
        "for f in glob.glob('/content/drive/My Drive/yelp_data/*'):\n",
        "    df_tmp = pd.read_csv(f)\n",
        "    df.append(df_tmp)\n",
        "df_all = pd.concat(df)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D7L_YwqujEnL",
        "colab_type": "code",
        "outputId": "72e34597-c8b5-4846-aa03-6f9262195df2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 632
        }
      },
      "source": [
        "df_all.head()\n",
        "# df_all = df_all.head(10000)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>business_id</th>\n",
              "      <th>cool</th>\n",
              "      <th>date</th>\n",
              "      <th>funny</th>\n",
              "      <th>review_id</th>\n",
              "      <th>stars</th>\n",
              "      <th>text</th>\n",
              "      <th>useful</th>\n",
              "      <th>user_id</th>\n",
              "      <th>lemmatize_text</th>\n",
              "      <th>stem_text</th>\n",
              "      <th>snowball_stem_text</th>\n",
              "      <th>text_clean</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>VLZPqnPatkdsz-w9aTGFNA</td>\n",
              "      <td>0</td>\n",
              "      <td>2014-06-15 23:14:17</td>\n",
              "      <td>0</td>\n",
              "      <td>KtX-oVw_tW7OM933iQulBw</td>\n",
              "      <td>5.0</td>\n",
              "      <td>literally wouldnt able find one negative thing...</td>\n",
              "      <td>12</td>\n",
              "      <td>S0b8_tFfOJjfERP4_bPMpQ</td>\n",
              "      <td>literally wouldnt able find one negative thing...</td>\n",
              "      <td>liter wouldnt abl find one neg thing say dr ma...</td>\n",
              "      <td>liter wouldnt abl find one negat thing say dr ...</td>\n",
              "      <td>liter wouldnt abl find one neg thing say dr ma...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>cMFe-S47UGetMkEXz5dhKQ</td>\n",
              "      <td>0</td>\n",
              "      <td>2016-11-26 16:10:10</td>\n",
              "      <td>0</td>\n",
              "      <td>I93niSj-jLMVAfjHV3bKQA</td>\n",
              "      <td>5.0</td>\n",
              "      <td>eric best im la needed gel mani pedi eric help...</td>\n",
              "      <td>1</td>\n",
              "      <td>U1bmnQo9aGTORC-dzFA42Q</td>\n",
              "      <td>eric best im la needed gel mani pedi eric help...</td>\n",
              "      <td>eric best im la need gel mani pedi eric help d...</td>\n",
              "      <td>eric best im la need gel mani pedi eric help d...</td>\n",
              "      <td>eric best im la need gel mani pedi eric help d...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>ZCsvwa_dsqNB8d8tYHPdjw</td>\n",
              "      <td>1</td>\n",
              "      <td>2009-03-14 21:11:47</td>\n",
              "      <td>1</td>\n",
              "      <td>NM4Fwh7VPINaiLA5bzbU-w</td>\n",
              "      <td>3.0</td>\n",
              "      <td>hate lesser rating review sir edmonds maybe do...</td>\n",
              "      <td>3</td>\n",
              "      <td>ZVu9TDpTvIgCN8x6IY-KmA</td>\n",
              "      <td>hate lesser rating review sir edmonds maybe do...</td>\n",
              "      <td>hate lesser rate review sir edmond mayb dozen ...</td>\n",
              "      <td>hate lesser rate review sir edmond mayb dozen ...</td>\n",
              "      <td>hate lesser rate review sir edmond mayb dozen ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>Ql5npMMRWKurN99tgA-g5w</td>\n",
              "      <td>0</td>\n",
              "      <td>2009-08-14 01:21:43</td>\n",
              "      <td>0</td>\n",
              "      <td>kb5Tl_Yyu919u7SzPaqQ0g</td>\n",
              "      <td>3.0</td>\n",
              "      <td>well staying 812 81409room nice upon looking g...</td>\n",
              "      <td>1</td>\n",
              "      <td>Dyn0ltgSpiCW3W2jqMVmlA</td>\n",
              "      <td>well staying 812 81409room nice upon looking g...</td>\n",
              "      <td>well stay 812 81409room nice upon look glass s...</td>\n",
              "      <td>well stay 812 81409room nice upon look glass s...</td>\n",
              "      <td>well stay room nice upon look glass shelf main...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>WRQ-9LluyivReFiQZFUujw</td>\n",
              "      <td>3</td>\n",
              "      <td>2014-08-27 21:27:25</td>\n",
              "      <td>2</td>\n",
              "      <td>YaW20QCEhXNTOrvJtADJuw</td>\n",
              "      <td>5.0</td>\n",
              "      <td>fast food place make great hot dog different f...</td>\n",
              "      <td>3</td>\n",
              "      <td>dXIO-WFQJ8pwQ5M2STewZA</td>\n",
              "      <td>fast food place make great hot dog different f...</td>\n",
              "      <td>fast food place make great hot dog differ flav...</td>\n",
              "      <td>fast food place make great hot dog differ flav...</td>\n",
              "      <td>fast food place make great hot dog differ flav...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  ...                                         text_clean\n",
              "0           0  ...  liter wouldnt abl find one neg thing say dr ma...\n",
              "1           1  ...  eric best im la need gel mani pedi eric help d...\n",
              "2           2  ...  hate lesser rate review sir edmond mayb dozen ...\n",
              "3           3  ...  well stay room nice upon look glass shelf main...\n",
              "4           4  ...  fast food place make great hot dog differ flav...\n",
              "\n",
              "[5 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gtHiDS1TsQLG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_df = pd.DataFrame([])\n",
        "data_df['x'] = df_all['text_clean'].apply(str)\n",
        "data_df['y'] = df_all.apply(lambda x: str(int(x.stars) - 1), axis=1)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SXwqN6mJlxf1",
        "colab_type": "code",
        "outputId": "85471656-a1fc-492e-9954-21ac2cd44645",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        }
      },
      "source": [
        "data_df.head(10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>x</th>\n",
              "      <th>y</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>liter wouldnt abl find one neg thing say dr ma...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>eric best im la need gel mani pedi eric help d...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>hate lesser rate review sir edmond mayb dozen ...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>well stay room nice upon look glass shelf main...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>fast food place make great hot dog differ flav...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>bakeri sey bet sweet buttercream cani ventur o...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>novelti legoland attract open toronto area cer...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>far biggest piec crap hotel ever servic slow b...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>coloni vietnames great place busi luncha huge ...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>favorit chipotl locat howev find order pick st...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   x  y\n",
              "0  liter wouldnt abl find one neg thing say dr ma...  4\n",
              "1  eric best im la need gel mani pedi eric help d...  4\n",
              "2  hate lesser rate review sir edmond mayb dozen ...  2\n",
              "3  well stay room nice upon look glass shelf main...  2\n",
              "4  fast food place make great hot dog differ flav...  4\n",
              "5  bakeri sey bet sweet buttercream cani ventur o...  3\n",
              "6  novelti legoland attract open toronto area cer...  1\n",
              "7  far biggest piec crap hotel ever servic slow b...  0\n",
              "8  coloni vietnames great place busi luncha huge ...  3\n",
              "9  favorit chipotl locat howev find order pick st...  3"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j08ShDMYYhm4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MAX_NB_WORDS = 10000\n",
        "MAX_SEQUENCE_LENGTH = 250\n",
        "EMBEDDING_DIM = 100\n",
        "\n",
        "tokenizer = Tokenizer(num_words=MAX_NB_WORDS, filters='!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~', lower=True)\n",
        "tokenizer.fit_on_texts(data_df['x'].values)\n",
        "word_index = tokenizer.word_index\n",
        "\n",
        "word_index = {k:(v+3) for k,v in word_index.items()}\n",
        "word_index[\"<PAD>\"] = 0\n",
        "word_index[\"<START>\"] = 1\n",
        "word_index[\"<UNK>\"] = 2  \n",
        "word_index[\"<UNUSED>\"] = 3\n",
        "\n",
        "tokenizer.word_index = word_index\n",
        "reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])\n",
        "\n",
        "def decode_review(text):\n",
        "    return ' '.join([reverse_word_index.get(i, '?') for i in text])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "obdU8XdgCRry",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_df['X'] = [x for x in X]\n",
        "data_df['Y'] = [y for y in Y]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xQwPfpNbm28U",
        "colab_type": "code",
        "outputId": "2792e01f-cbba-4dc6-d301-24e5f1f360c3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "X = tokenizer.texts_to_sequences(data_df['x'].values)\n",
        "X = pad_sequences(X, maxlen=MAX_SEQUENCE_LENGTH)\n",
        "print('Shape of data tensor:', X.shape)\n",
        "\n",
        "Y = data_df['y'].values\n",
        "print('Shape of label tensor:', Y.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of data tensor: (1000000, 250)\n",
            "Shape of label tensor: (1000000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oMbC7kBP6J6H",
        "colab_type": "code",
        "outputId": "982b5e31-babf-43a7-dbe8-51f733021a34",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "tokenizer.sequences_to_texts([[1]])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['place']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_PmPFh910-Vv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Y = to_categorical(Y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oxuv2f6qmr-g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.33, random_state=42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "As3Gd4Pnmr31",
        "colab_type": "code",
        "outputId": "17297b04-d748-4dcb-9d83-731852098387",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "embedding_dim = 64\n",
        "categoty_dim = len(Y[0])\n",
        "vocab_size = MAX_NB_WORDS\n",
        "\n",
        "callback = keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n",
        "\n",
        "model = keras.Sequential([\n",
        "    layers.Embedding(vocab_size, embedding_dim, input_length=MAX_SEQUENCE_LENGTH),\n",
        "    layers.GlobalAveragePooling1D(),\n",
        "    layers.Dense(128, activation='relu'),\n",
        "    layers.Dense(categoty_dim, activation='softmax')\n",
        "])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 250, 64)           640000    \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d (Gl (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 128)               8320      \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 5)                 645       \n",
            "=================================================================\n",
            "Total params: 648,965\n",
            "Trainable params: 648,965\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HRLOfq0XlfAy",
        "colab_type": "code",
        "outputId": "e4d1769f-28aa-46d5-e0ef-a8ba05021afc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 496
        }
      },
      "source": [
        "model.compile(optimizer='adam',\n",
        "             loss='categorical_crossentropy',\n",
        "             metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(X_train, y_train, epochs=30, batch_size=512, callbacks=[callback], validation_split=0.2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0822 20:18:09.002000 140219588122496 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 536000 samples, validate on 134000 samples\n",
            "Epoch 1/30\n",
            "536000/536000 [==============================] - 27s 51us/sample - loss: 0.9542 - accuracy: 0.6063 - val_loss: 0.8041 - val_accuracy: 0.6640\n",
            "Epoch 2/30\n",
            "536000/536000 [==============================] - 26s 49us/sample - loss: 0.7845 - accuracy: 0.6699 - val_loss: 0.7896 - val_accuracy: 0.6676\n",
            "Epoch 3/30\n",
            "536000/536000 [==============================] - 26s 49us/sample - loss: 0.7705 - accuracy: 0.6751 - val_loss: 0.7840 - val_accuracy: 0.6691\n",
            "Epoch 4/30\n",
            "536000/536000 [==============================] - 26s 49us/sample - loss: 0.7632 - accuracy: 0.6779 - val_loss: 0.7813 - val_accuracy: 0.6705\n",
            "Epoch 5/30\n",
            "536000/536000 [==============================] - 26s 49us/sample - loss: 0.7567 - accuracy: 0.6805 - val_loss: 0.7773 - val_accuracy: 0.6722\n",
            "Epoch 6/30\n",
            "536000/536000 [==============================] - 26s 49us/sample - loss: 0.7498 - accuracy: 0.6840 - val_loss: 0.7751 - val_accuracy: 0.6731\n",
            "Epoch 7/30\n",
            "536000/536000 [==============================] - 26s 49us/sample - loss: 0.7439 - accuracy: 0.6865 - val_loss: 0.7760 - val_accuracy: 0.6734\n",
            "Epoch 8/30\n",
            "536000/536000 [==============================] - 26s 48us/sample - loss: 0.7397 - accuracy: 0.6881 - val_loss: 0.7769 - val_accuracy: 0.6732\n",
            "Epoch 9/30\n",
            "536000/536000 [==============================] - 26s 48us/sample - loss: 0.7350 - accuracy: 0.6905 - val_loss: 0.7770 - val_accuracy: 0.6726\n",
            "Epoch 10/30\n",
            "536000/536000 [==============================] - 26s 48us/sample - loss: 0.7308 - accuracy: 0.6921 - val_loss: 0.7784 - val_accuracy: 0.6712\n",
            "Epoch 11/30\n",
            "536000/536000 [==============================] - 26s 48us/sample - loss: 0.7262 - accuracy: 0.6942 - val_loss: 0.7782 - val_accuracy: 0.6728\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "chByTTNfrD7n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "history_dict = history.history\n",
        "\n",
        "acc = history_dict['accuracy']\n",
        "val_acc = history_dict['val_accuracy']\n",
        "loss = history_dict['loss']\n",
        "val_loss = history_dict['val_loss']\n",
        "\n",
        "epochs = range(1, len(acc) + 1)\n",
        "\n",
        "plt.figure(figsize=(12,9))\n",
        "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "print(acc)\n",
        "print(val_acc)\n",
        "plt.figure(figsize=(12,9))\n",
        "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.ylim((0.5,1))\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uAegQTxHsRCu",
        "colab_type": "code",
        "outputId": "af4e3016-c0c4-4317-a3fb-b9fdbd8e283b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "e = model.layers[0]\n",
        "weights = e.get_weights()[0]\n",
        "print(weights.shape) "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(10000, 64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KEZa84Ep69HQ",
        "colab_type": "code",
        "outputId": "5e034d40-aeb0-44d0-b48f-2f93ee241ae9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(tokenizer.word_index)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "580165"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zMC_uGDKBWo7",
        "colab_type": "code",
        "outputId": "76d343f7-be1b-4741-afc0-83f516bcc100",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 510
        }
      },
      "source": [
        "for word_num in range(2):\n",
        "    word = decode_review([word_num])\n",
        "    embeddings = weights[word_num]\n",
        "    print(word)\n",
        "    print(embeddings)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<PAD>\n",
            "[ 3.08487732e-02 -2.14942116e-02 -7.30865262e-03 -1.79397166e-02\n",
            " -2.50233861e-04  2.85194861e-03  1.61988451e-03  2.72491723e-02\n",
            " -1.59611702e-02  1.92714890e-03  2.98261493e-02 -1.82294007e-02\n",
            "  4.06449251e-02 -6.73580635e-03 -1.80583680e-03  2.97009274e-02\n",
            "  2.19542533e-02 -5.65636996e-03  5.88051043e-05  1.87239442e-02\n",
            " -1.11676361e-02  1.81353744e-02 -2.46090740e-02 -1.08185485e-02\n",
            " -3.02369129e-02 -1.83733162e-02 -3.51357623e-03  2.95726936e-02\n",
            "  1.17655676e-02  3.21063213e-02 -4.52863518e-03 -2.98990458e-02\n",
            " -2.28876043e-02 -1.62423011e-02  2.13906765e-02 -3.12791988e-02\n",
            "  2.53675282e-02 -2.86115538e-02  1.58105802e-03  2.68167723e-02\n",
            " -2.12304275e-02 -6.58813445e-03 -1.07218660e-02 -1.09538285e-03\n",
            "  2.18073698e-03 -8.17233871e-04  1.54988244e-02  3.90542224e-02\n",
            " -7.90382829e-03 -3.99258127e-03 -2.90282331e-02  3.05142961e-02\n",
            "  6.75792154e-03 -1.65091567e-02 -1.62716247e-02  2.74020503e-03\n",
            "  3.79621871e-02  4.31279698e-03 -1.24085210e-02 -2.79991478e-02\n",
            "  2.63660699e-02 -2.33923234e-02 -3.82678807e-02 -1.13815013e-02]\n",
            "<START>\n",
            "[ 0.00840801  0.01293193  0.04725099 -0.01829188  0.00763215  0.01475556\n",
            "  0.02887174  0.02839837 -0.02960869 -0.01212293 -0.00174488 -0.00655903\n",
            " -0.02880517 -0.03210006  0.02367629  0.00908406 -0.03223312 -0.03673457\n",
            "  0.039627    0.04365262 -0.049682   -0.02350396 -0.02264353  0.00544597\n",
            " -0.00966139  0.0430926   0.03878606 -0.01606356  0.02321345  0.00589166\n",
            "  0.023664    0.01748481  0.00976788  0.04785559  0.0121667  -0.0459565\n",
            " -0.01684039 -0.00765311 -0.01699651  0.0354363   0.03682965  0.01479251\n",
            " -0.04517552  0.04461649  0.01333997  0.007179   -0.02550851 -0.01539484\n",
            "  0.0181237  -0.01051014 -0.0329081   0.03264514 -0.02705777  0.03184534\n",
            "  0.02696839  0.00103569  0.0024127  -0.01236974 -0.01299062  0.03896597\n",
            "  0.00440663 -0.00031104  0.00059665  0.00236458]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fFxrvcreCq8m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_df[['X', 'Y']].to_pickle(\"drive/My Drive/word2vec/data_vectorized.pickle\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y53po6CkSr9M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "a = pd.read_pickle(\"drive/My Drive/word2vec/data_vectorized.pickle\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3DZBOUHvC8ml",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('drive/My Drive/word2vec/tokenizer.pickle', 'wb') as handle:\n",
        "    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OdUnKP1MLYJ8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('drive/My Drive/word2vec/tokenizer.pickle', 'rb') as handle:\n",
        "    tokenizer = pickle.load(handle)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SAOiq9jZMvwt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import io"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hcPYALUQNGfe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.savetxt(\"drive/My Drive/word2vec/embedding_weights.txt\", weights)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IfRO0SKjNOBr",
        "colab_type": "code",
        "outputId": "33cc9ed7-f78e-43a8-88ee-8bdeec46f2c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "weights = np.loadtxt(\"drive/My Drive/word2vec/embedding_weights.txt\")\n",
        "weights"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 3.08487732e-02, -2.14942116e-02, -7.30865262e-03, ...,\n",
              "        -2.33923234e-02, -3.82678807e-02, -1.13815013e-02],\n",
              "       [ 8.40801001e-03,  1.29319318e-02,  4.72509898e-02, ...,\n",
              "        -3.11039388e-04,  5.96653670e-04,  2.36457586e-03],\n",
              "       [-1.30274147e-03, -1.52882561e-02, -4.59729917e-02, ...,\n",
              "         6.82564825e-03,  4.04343493e-02, -3.36878188e-02],\n",
              "       ...,\n",
              "       [ 1.64468780e-01, -1.35418892e-01, -1.18391640e-01, ...,\n",
              "        -5.36593087e-02, -2.52245486e-01, -9.96467546e-02],\n",
              "       [-4.50488657e-01, -6.22870065e-02, -1.10623036e-02, ...,\n",
              "         2.36492530e-02, -1.43581361e-01,  3.36197764e-02],\n",
              "       [-6.68856427e-02, -1.01810165e-01, -2.32698068e-01, ...,\n",
              "        -1.25630215e-01, -2.63715945e-02,  2.60064274e-01]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jPOKaPc7MQxA",
        "colab_type": "code",
        "outputId": "001f72d8-e4b5-4aab-e12a-3b96318dfbb6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "weights.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 64)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tcruc3nk69D0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import io\n",
        "\n",
        "out_v = io.open(\"drive/My Drive/word2vec/vecs.tsv\", 'w', encoding='utf-8')\n",
        "out_m = io.open(\"drive/My Drive/word2vec/meta.tsv\", 'w', encoding='utf-8')\n",
        "for word_num in range(vocab_size-4):\n",
        "    word = decode_review([word_num])\n",
        "    embeddings = weights[word_num]\n",
        "    out_m.write(word + \"\\n\")\n",
        "    out_v.write('\\t'.join([str(x) for x in embeddings]) + \"\\n\")\n",
        "out_v.close()\n",
        "out_m.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZbFl6W1euO9W",
        "colab_type": "code",
        "outputId": "590ee965-db2c-4d59-ac46-1f8e4186a89c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "from google.colab import files\n",
        "print(1)\n",
        "files.download(\"drive/My Drive/word2vec/vecs.tsv\")\n",
        "print(2)\n",
        "files.download(\"drive/My Drive/word2vec/meta.tsv\")\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1\n",
            "2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jrdlCe8HN7FZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}